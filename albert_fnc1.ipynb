{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "name": "test_albert.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielvangelder/Applied-NLP-Project-IN4325/blob/main/albert_fnc1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qbezGHkiqCS"
      },
      "source": [
        "### Using ALBERT on the FNC-1 data set\n",
        "First download the [FNC-1 dataset](http://www.fakenewschallenge.org). Then mount drive and install libraries.\n",
        "If you get a TQDM Metafile error, re-run this code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DVjYafjth0n"
      },
      "source": [
        "PRETRAINED_MODEL_LOCATION = 'drive/My Drive/IR-Files/albert_all_train/'\n",
        "MODEL_OUT_LOCATION = 'drive/My Drive/IR-Files/albert/'\n",
        "FNC1_LOCATION = 'drive/My Drive/IR-Files/fnc-1/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iLskeat6x67"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install tqdm\n",
        "!pip install simpletransformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4j8Iitxi-u4"
      },
      "source": [
        "### Data reader class\n",
        "Reads the data set and performs scoring and data splitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPaQC4SW6LGX"
      },
      "source": [
        "from typing import List, Union\n",
        "\n",
        "import pandas as pd\n",
        "from math import ceil\n",
        "import numpy as np\n",
        "\n",
        "class Fnc1Reader:\n",
        "    \"\"\"Reads the Fake News Detection data set.\"\"\"\n",
        "\n",
        "    def __init__(self, loc: str):\n",
        "        \"\"\"Inits the data reader with the data at the given location. Expects train and test set data.\"\"\"\n",
        "        self.loc = loc\n",
        "        if self.loc[len(loc) - 1] != '/':\n",
        "            self.loc += '/'\n",
        "        self.train_bodies, self.train_stances = self.read_train()\n",
        "        self.test_bodies, self.test_stances = self.read_test()\n",
        "        self.comp_bodies, self.comp_stances = self.read_comp()\n",
        "\n",
        "    def read_train(self) -> [pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\"Reads the train set from the data location.\"\"\"\n",
        "        return self.read_labelled('train_bodies.csv', 'train_stances.csv')\n",
        "\n",
        "    def read_comp(self) -> [pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\"Reads the competition data set from the data location\"\"\"\n",
        "        return self.read_labelled('competition_test_bodies.csv', 'competition_test_stances.csv')\n",
        "\n",
        "    def read_labelled(self, bodies_loc: str, stances_loc: str) -> [pd.DataFrame, pd.DataFrame]:\n",
        "        bodies = pd.read_csv(self.loc + bodies_loc, names=['Body ID', 'articleBody'], header=0)\n",
        "        stances = pd.read_csv(self.loc + stances_loc, names=['Headline', 'Body ID', 'Stance'], header=0)\n",
        "        labels = list(map(self.stance_to_label, stances['Stance'].to_list()))\n",
        "        stances['Label'] = labels\n",
        "        assert len(bodies) != 0 and len(stances) != 0\n",
        "        assert bodies.columns.to_list() == ['Body ID', 'articleBody'] \\\n",
        "               and stances.columns.to_list() == ['Headline', 'Body ID', 'Stance', 'Label']\n",
        "\n",
        "        return bodies, stances\n",
        "\n",
        "    def stance_to_label(self, stance: str) -> int:\n",
        "        \"\"\"\n",
        "        1, Agrees: The body text agrees with the headline.\n",
        "        2, Disagrees: The body text disagrees with the headline.\n",
        "        3, Discusses: The body text discuss the same topic as the headline, but does not take a position\n",
        "        4, Unrelated: The body text discusses a different topic than the headline\n",
        "        \"\"\"\n",
        "        if stance == 'agree':\n",
        "            return 0\n",
        "        elif stance == 'disagree':\n",
        "            return 1\n",
        "        elif stance == 'discuss':\n",
        "            return 2\n",
        "        elif stance == 'unrelated':\n",
        "            return 3\n",
        "        raise Exception('Stance does not exist: ' + stance)\n",
        "\n",
        "    def read_test(self) -> [pd.DataFrame, pd.DataFrame]:\n",
        "        \"\"\"Reads the test set from the data location.\"\"\"\n",
        "        bodies = pd.read_csv(self.loc + 'train_bodies.csv', names=['Body ID', 'articleBody'], header=0)\n",
        "        stances = pd.read_csv(self.loc + 'train_stances.csv', names=['Headline', 'Body ID'], header=0)\n",
        "        assert len(bodies) != 0 and len(stances) != 0\n",
        "        assert bodies.columns.to_list() == ['Body ID', 'articleBody'] \\\n",
        "               and stances.columns.to_list() == ['Headline', 'Body ID']\n",
        "\n",
        "        return bodies, stances\n",
        "\n",
        "    def kfold(self, n: int) -> List[pd.DataFrame]:\n",
        "        \"\"\"Returns a list of n random folds of the training set.\"\"\"\n",
        "        size = len(self.train_stances.index)\n",
        "        shuffled = self.train_stances.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "        folds = []\n",
        "        for i in range(0, n - 1):\n",
        "            lower = ceil(i / n * size)\n",
        "            upper = ceil((i + 1) / n * size)\n",
        "            if i == n - 1:\n",
        "                upper = size\n",
        "            fold = shuffled.iloc[lower:upper]\n",
        "            folds.append(fold.reset_index(drop=True))\n",
        "\n",
        "        return folds\n",
        "\n",
        "    def get_body_train(self, body_id: int) -> str:\n",
        "        \"\"\"Returns the right body text from the train set.\"\"\"\n",
        "        bodies = self.train_bodies.loc[self.train_bodies['Body ID'] == body_id]['articleBody'].to_list()\n",
        "        if len(bodies) == 0:\n",
        "            raise Exception('No body with ID', str(body_id))\n",
        "        return bodies[0]\n",
        "    \n",
        "    def get_body_test(self, body_id: int) -> str:\n",
        "        \"\"\"Returns the right body text from the train set.\"\"\"\n",
        "        bodies = self.test_bodies.loc[self.test_bodies['Body ID'] == body_id]['articleBody'].to_list()\n",
        "        if len(bodies) == 0:\n",
        "            raise Exception('No body with ID', str(body_id))\n",
        "        return bodies[0]\n",
        "    \n",
        "    def get_body_comp(self, body_id: int) -> str:\n",
        "        \"\"\"Returns the right body text from the train set.\"\"\"\n",
        "        bodies = self.comp_bodies.loc[self.comp_bodies['Body ID'] == body_id]['articleBody'].to_list()\n",
        "        if len(bodies) == 0:\n",
        "            raise Exception('No body with ID', str(body_id))\n",
        "        return bodies[0]\n",
        "\n",
        "    def evaluate_comp(self, labels: Union[List[int], List[str]]) -> float:\n",
        "        \"\"\"Evaluates the given labels on the competition data set.\"\"\"\n",
        "        if all(isinstance(label, int) for label in labels):\n",
        "            return self.evaluate_fold(self.comp_stances, labels)\n",
        "        elif all(isinstance(label, str) for label in labels):\n",
        "            return self.evaluate_fold(self.comp_stances, list(map(self.stance_to_label, labels)))\n",
        "        else:\n",
        "            raise Exception('Bad labels format: ' + str(type(labels)))\n",
        "\n",
        "    def evaluate_fold(self, fold: pd.DataFrame, labels: List[int]) -> float:\n",
        "        \"\"\"Evaluates a data fold with the given labels\"\"\"\n",
        "        assert len(fold.index) == len(labels)\n",
        "        score = 0\n",
        "        for i, row in fold.iterrows():\n",
        "            score += self.score(row['labels'], labels[i])\n",
        "        return score\n",
        "\n",
        "    def score(self, actual: int, output: int) -> float:\n",
        "        \"\"\"\n",
        "        As in scorer.py provided by FNC-1.\n",
        "        +0.25 for each correct unrelated\n",
        "        +0.25 for each correct related (label is any of agree, disagree, discuss)\n",
        "        +0.75 for each correct agree, disagree, discuss\n",
        "        \"\"\"\n",
        "        assert output in [0, 1, 2, 3]\n",
        "        score = 0\n",
        "        if actual == output:\n",
        "            score += 0.25\n",
        "            if actual != 3:\n",
        "                score += 0.50\n",
        "        if actual in [0, 1, 2] and output in [0, 1, 2]:\n",
        "            score += 0.25\n",
        "        return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wkw7cFVajGq8"
      },
      "source": [
        "### Training the model\n",
        "The ALBERT model is trained on the whole train set with 5 epochs and batches of size 10. (When loading the model externally you can skip this step)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5eZVhuHF59E3"
      },
      "source": [
        "import pandas as pd\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "\n",
        "def fold_to_transf_input(fold: pd.DataFrame, reader: Fnc1Reader):\n",
        "    assert fold.columns.tolist() == ['Headline', 'Body ID', 'Stance', 'Label']\n",
        "    result = fold.copy()\n",
        "    result['Body ID'] = result['Body ID'].map(reader.get_body_train)\n",
        "    del result['Stance']\n",
        "    result = result.rename(columns={'Headline': 'text_a', 'Body ID': 'text_b', 'Label': 'labels'})\n",
        "    return result\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    reader = Fnc1Reader(FNC1_LOCATION)\n",
        "    data = fold_to_transf_input(reader.train_stances, reader)\n",
        "\n",
        "    model = ClassificationModel('albert', 'albert-base-v2', num_labels=4, use_cuda=True, args={\n",
        "        'learning_rate':3e-5,\n",
        "        'num_train_epochs': 5,\n",
        "        'reprocess_input_data': True,\n",
        "        'overwrite_output_dir': True,\n",
        "        'process_count': 10,\n",
        "        'train_batch_size': 10,\n",
        "        'eval_batch_size': 4,\n",
        "        'max_seq_length': 512,\n",
        "        'fp16': True,\n",
        "        'output_dir': MODEL_OUT_LOCATION,\n",
        "        'best_model_dir': MODEL_OUT_LOCATION + 'best/',\n",
        "    })\n",
        "\n",
        "    model.train_model(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IERPhT6sjfDv"
      },
      "source": [
        "### Evaluating the model\n",
        "The FNC-1 scoring function is used to evaluate the model on the competition set. The model is loaded from the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtBYVw7J-aLD"
      },
      "source": [
        "import pandas as pd\n",
        "from simpletransformers.classification import ClassificationModel\n",
        "\n",
        "def output_to_labels(output):\n",
        "    output_labels = []\n",
        "\n",
        "    for o in output:\n",
        "        max = o[0]\n",
        "        i_max = 0\n",
        "        for i in range(1, len(o)):\n",
        "            if (o[i] > max):\n",
        "                max = o[i]\n",
        "                i_max = i\n",
        "        output_labels.append(i_max)\n",
        "    \n",
        "    return output_labels\n",
        "\n",
        "def fold_to_transf_input_comp(fold: pd.DataFrame, reader: Fnc1Reader):\n",
        "    assert fold.columns.tolist() == ['Headline', 'Body ID', 'Stance', 'Label']\n",
        "    result = fold.copy()\n",
        "    result['Body ID'] = result['Body ID'].map(reader.get_body_comp)\n",
        "    del result['Stance']\n",
        "    result = result.rename(columns={'Headline': 'text_a', 'Body ID': 'text_b', 'Label': 'labels'})\n",
        "    return result\n",
        "\n",
        "# Comment this model declaration to use the trained model.\n",
        "model = ClassificationModel('albert', PRETRAINED_MODEL_LOCATION, num_labels=4, use_cuda=True, args={\n",
        "        'learning_rate':3e-5,\n",
        "        'num_train_epochs': 5,\n",
        "        'reprocess_input_data': True,\n",
        "        'overwrite_output_dir': True,\n",
        "        'process_count': 10,\n",
        "        'train_batch_size': 10,\n",
        "        'eval_batch_size': 4,\n",
        "        'max_seq_length': 512,\n",
        "        'fp16': True,\n",
        "    })\n",
        "\n",
        "def labels_to_stances(labels):\n",
        "    stances = []\n",
        "    for l in labels:\n",
        "        if l == 0:\n",
        "            stances.append('agree')\n",
        "        elif l == 1:\n",
        "            stances.append('disagree')\n",
        "        elif l == 2:\n",
        "            stances.append('discuss')\n",
        "        elif l == 3:\n",
        "            stances.append('unrelated')\n",
        "    return stances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUUXED2ngCdc"
      },
      "source": [
        "reader = Fnc1Reader(FNC1_LOCATION)\n",
        "test_data = fold_to_transf_input_comp(reader.comp_stances, reader)\n",
        "_, output, _ = model.eval_model(test_data)\n",
        "output_labels = output_to_labels(output)\n",
        "print(reader.evaluate_fold(test_data, output_labels))\n",
        "\n",
        "output_stances = labels_to_stances(output_labels)\n",
        "csv = pd.read_csv(FNC1_LOCATION + 'competition_test_stances.csv', header=0)\n",
        "csv['Stance'] = output_stances\n",
        "csv.to_csv(FNC1_LOCATION + 'albert_test_output.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9g3jBS-vdZbF"
      },
      "source": [
        "## Gender Bias Analysis\n",
        "In order to perform gender bias analysis, we must first create an augmented data set in which all gender definitions are flipped."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX5vhZwLdjqX"
      },
      "source": [
        "!pip install spacy\n",
        "!pip install faker\n",
        "!pip install gender_guesser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LNwfvUpdl8t"
      },
      "source": [
        "import spacy\n",
        "import faker\n",
        "import gender_guesser.detector as gender\n",
        "\n",
        "reader = Fnc1Reader(FNC1_LOCATION)\n",
        "s = reader.get_body_train(0)\n",
        "\n",
        "f = faker.Faker()\n",
        "d = gender.Detector()\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def create_person_mapping(line):\n",
        "    \"\"\" Creates a person name mapping from male to female or vice-versa. \"\"\"\n",
        "    parsed = nlp(line)\n",
        "    persons = [ent.text for ent in parsed.ents if ent.label_ == 'PERSON']\n",
        "\n",
        "    replaces = {}\n",
        "    for person in persons:\n",
        "        s = person.split(' ')\n",
        "        g = d.get_gender(s[0])\n",
        "        result = ''\n",
        "        if g == 'male':\n",
        "            fn = f.first_name_female()\n",
        "            replaces[s[0]] = fn\n",
        "            result += fn\n",
        "        elif g == 'female':\n",
        "            fn = f.first_name_male()\n",
        "            replaces[s[0]] = fn\n",
        "            result += fn\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if len(s) > 1:\n",
        "            result += ' ' + ' '.join(s[1:])\n",
        "        replaces[person] = result\n",
        "\n",
        "    return replaces\n",
        "\n",
        "def flip_genders(line, mapping, count):\n",
        "    \"\"\" \n",
        "    Flips all gender definitions in a piece of text. Keeps track of the amount\n",
        "    of changes in `count`.\n",
        "    \"\"\"\n",
        "    res = ''\n",
        "    doc = nlp(line)\n",
        "    for ent in doc:\n",
        "        replace = ''\n",
        "        if ent.text.lower() == 'he':\n",
        "            replace += 'she'\n",
        "        elif ent.text.lower() == 'him' or ent.text.lower() == 'his':\n",
        "            replace += 'her'\n",
        "        elif ent.text.lower() == 'she':\n",
        "            replace += 'he'\n",
        "        elif ent.text.lower() == 'her' and ent.tag_ == 'PRP$':\n",
        "            replace += 'his'\n",
        "        elif ent.text.lower() == 'her' and ent.tag_ == 'PRP':\n",
        "            replace += 'him'\n",
        "        elif ent.text.lower == 'man':\n",
        "            replace += 'woman'\n",
        "        elif ent.text.lower == 'woman':\n",
        "            replace += 'man'\n",
        "        else:\n",
        "            replace += ent.text\n",
        "            count[0] -= 1\n",
        "        count[0] += 1\n",
        "        if ent.text[0].isupper():\n",
        "            replace = replace[0].upper() + replace[1:]\n",
        "        res += replace + ' ' * (len(ent.text_with_ws) - len(ent.text))\n",
        "\n",
        "    #TODO: This could swap one name multiple times\n",
        "    for name in mapping:\n",
        "        if name in line:\n",
        "            count[1] += line.count(name)\n",
        "            res = res.replace(name, mapping[name])\n",
        "\n",
        "    return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja5FI4LjvEFk"
      },
      "source": [
        "Creates the augmented test set. Can be skipped if it already exists on your drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRmi5XFJdtVI"
      },
      "source": [
        "mapping = {}\n",
        "\n",
        "augmented_bodies = reader.comp_bodies.copy()\n",
        "augmented_stances = reader.comp_stances.copy()\n",
        "\n",
        "for i, row in augmented_stances.iterrows():\n",
        "    m = create_person_mapping(row['Headline'])\n",
        "    for k in m:\n",
        "        if k not in mapping:\n",
        "            mapping[k] = m[k]\n",
        "\n",
        "for i, row in augmented_bodies.iterrows():\n",
        "    m = create_person_mapping(row['articleBody'])\n",
        "    for k in m:\n",
        "        if k not in mapping:\n",
        "            mapping[k] = m[k]\n",
        "\n",
        "count = [0, 0]\n",
        "\n",
        "augmented_stances['Headline'] = augmented_stances['Headline'].map(lambda r: flip_genders(r, mapping, count))\n",
        "del augmented_stances['Label']\n",
        "augmented_bodies['articleBody'] = augmented_bodies['articleBody'].map(lambda r: flip_genders(r, mapping, count))\n",
        "\n",
        "print(count)\n",
        "\n",
        "augmented_stances.to_csv(FNC1_LOCATION + 'augmented_test_stances.csv', index=False)\n",
        "augmented_bodies.to_csv(FNC1_LOCATION + 'augmented_test_bodies.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8_-JfQ3vLke"
      },
      "source": [
        "Reads the augmented test set from the drive and evaluates the performance of the fine tuned model. Then writes the generated labels to the drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvO6gnjvd75g"
      },
      "source": [
        "reader = Fnc1Reader(FNC1_LOCATION)\n",
        "reader.comp_bodies, reader.comp_stances = reader.read_labelled('augmented_test_bodies.csv', \n",
        "                                                            'augmented_test_stances.csv')\n",
        "test_data = fold_to_transf_input_comp(reader.comp_stances, reader)\n",
        "_, output, _ = model.eval_model(test_data)\n",
        "output_labels = output_to_labels(output)\n",
        "print(reader.evaluate_fold(test_data, output_labels))\n",
        "\n",
        "output_stances = labels_to_stances(output_labels)\n",
        "csv = pd.read_csv(FNC1_LOCATION + 'competition_test_stances.csv', header=0)\n",
        "csv['Stance'] = output_stances\n",
        "csv.to_csv(FNC1_LOCATION + 'albert_test_augmented_output.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}