{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "architectural-gathering",
   "metadata": {},
   "source": [
    "# Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "# stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_BODIES_PATH = \"data/fnc-1/competition_test_bodies.csv\"\n",
    "TEST_STANCES_PATH = \"data/fnc-1/competition_test_stances.csv\"\n",
    "TRAIN_BODIES_PATH = \"data/fnc-1/train_bodies.csv\"\n",
    "TRAIN_STANCES_PATH = \"data/fnc-1/train_stances.csv\"\n",
    "ALBERT_PREDICTIONS = \"data/fnc-1/golden_labels_2.csv\"\n",
    "BASELINE_PREDICTIONS = \"data/fnc-1/baseline_output.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-twelve",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_merged_df(bodies_path, stances_path):\n",
    "    bodies = pd.read_csv(bodies_path, names=['Body ID', 'articleBody'], header=0)\n",
    "    stances = pd.read_csv(stances_path, names=['Headline', 'Body ID', 'Stance'], header=0)\n",
    "    df = pd.merge(bodies, stances, on='Body ID')\n",
    "    return df\n",
    "\n",
    "\n",
    "albert = pd.read_csv(ALBERT_PREDICTIONS, names=['Headline', 'Body ID', 'Stance'], header=0)\n",
    "baseline = pd.read_csv(BASELINE_PREDICTIONS, names=['Headline', 'Body ID', 'Stance'], header=0)\n",
    "baseline.columns = ['Headline', 'Body ID', 'Stance_baseline']\n",
    "test_res = create_merged_df(TEST_BODIES_PATH, TEST_STANCES_PATH)\n",
    "# test_res['albert'] = pd.malbert[['Headline', 'Stance']]\n",
    "test_res = pd.merge(test_res,albert, on=['Headline', 'Body ID'], suffixes=['_true', '_albert'])\n",
    "test_res = pd.merge(test_res,baseline, on=['Headline', 'Body ID'])\n",
    "train = create_merged_df(TRAIN_BODIES_PATH, TRAIN_STANCES_PATH)\n",
    "# display(test_res)\n",
    "# display(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_res_rel = test_res.loc[test_res['Stance_true'] != 'unrelated']\n",
    "correct = test_res_rel.copy()\n",
    "correct['correct_albert'] = test_res_rel['Stance_true'] == test_res_rel['Stance_albert']\n",
    "correct['correct_base'] = test_res_rel['Stance_true'] == test_res_rel['Stance_baseline']\n",
    "correct = correct[['articleBody', 'Headline', 'Stance_true', 'correct_albert', 'correct_base']]\n",
    "# display(correct)\n",
    "correct_count = correct[['Headline', 'correct_albert', 'correct_base']].groupby(['Headline']).sum().sort_values('correct_albert', ascending=False)\n",
    "correct_count.reset_index(level=0, inplace=True)\n",
    "# display(correct_count)\n",
    "pair_count = {}\n",
    "rel_headlines = set(test_res_rel['Headline'].values)\n",
    "# print(rel_headlines)\n",
    "for head in rel_headlines:\n",
    "    pair_count[head] = test_res_rel.loc[test_res_rel['Headline'] == head].shape[0]\n",
    "    \n",
    "grouped_res = correct_count.copy()\n",
    "missed_count_albert = []\n",
    "missed_count_base = []\n",
    "total = []\n",
    "\n",
    "for headline in grouped_res['Headline'].values:\n",
    "    total.append(pair_count[headline])\n",
    "    missed_count_albert.append(pair_count[headline] - grouped_res.loc[grouped_res['Headline'] == headline]['correct_albert'].values[0])\n",
    "    missed_count_base.append(pair_count[headline] - grouped_res.loc[grouped_res['Headline'] == headline]['correct_base'].values[0])\n",
    "     \n",
    "grouped_res['missed_albert'] = missed_count_albert\n",
    "grouped_res['missed_base'] = missed_count_base\n",
    "grouped_res['total'] = total\n",
    "\n",
    "grouped_res['prop_albert'] = grouped_res['correct_albert'] / grouped_res['total']\n",
    "grouped_res['prop_base'] = grouped_res['correct_base'] / grouped_res['total']\n",
    "\n",
    "grouped_res['difference'] = grouped_res['correct_albert'] - grouped_res['correct_base']\n",
    "display(grouped_res)\n",
    "# display(grouped_res.loc[grouped_res['total'] > 20].sort_values('prop_albert', ascending=False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sporting-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_success = grouped_res.loc[grouped_res['prop_albert'] > 0.99]['Headline'].values\n",
    "headlines_failed = grouped_res.loc[grouped_res['prop_albert'] < 0.01]['Headline'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-defendant",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-birthday",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_dict = {}\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "            token_dict[result[-1]] = token\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-ferry",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_sample = headlines_success[0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_success_proc = list(map(preprocess, headlines_success))\n",
    "headlines_failed_proc = list(map(preprocess, headlines_failed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(headlines_success[5],headlines_success_proc[5])\n",
    "print(headlines_failed[5],headlines_failed_proc[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-sunday",
   "metadata": {},
   "source": [
    "A very crude tokenizer indeed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strategic-exhibit",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_success = gensim.corpora.Dictionary(headlines_success_proc)\n",
    "dictionary_success.filter_extremes(no_above=0.5, keep_n=100000)\n",
    "dictionary_failed = gensim.corpora.Dictionary(headlines_failed_proc)\n",
    "dictionary_failed.filter_extremes(no_above=0.5, keep_n=100000)\n",
    "bow_corpus_success = [dictionary_success.doc2bow(doc) for doc in headlines_success_proc]\n",
    "bow_corpus_failed = [dictionary_failed.doc2bow(doc) for doc in headlines_failed_proc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 99\n",
    "for i in range(len(bow_corpus_success[t])):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_corpus_success[t][i][0], dictionary_success[bow_corpus_success[t][i][0]], \n",
    "bow_corpus_success[t][i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-cleaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Topic modelling success...\")\n",
    "lda_model_sucess = gensim.models.LdaMulticore(bow_corpus_success, num_topics=10, id2word=dictionary_success, passes=2, workers=4)\n",
    "print(\"Topic modelling failed...\")\n",
    "lda_model_failed = gensim.models.LdaMulticore(bow_corpus_failed, num_topics=10, id2word=dictionary_failed, passes=2, workers=4)\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-bottom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, topic in lda_model_sucess.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "for i in range(10):\n",
    "    print([token_dict[p[0]] for p in lda_model_sucess.show_topic(i, topn=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-oxford",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx, topic in lda_model_failed.print_topics(-1):\n",
    "#     print('Topic: {} \\nWords: {}'.format(idx, topic))\n",
    "for i in range(10):\n",
    "    print([token_dict[p[0]] for p in lda_model_failed.show_topic(i, topn=10)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
